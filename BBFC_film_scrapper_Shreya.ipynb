{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy7SKUv21MiY"
      },
      "source": [
        "Script to extract movie details from BBFC site and convert the same into Pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zF4lSaimWjS5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "'''Function which scrapes recently rated page on BBFC site'''\n",
        "def recent_page_film_scrape():\n",
        "    '''\n",
        "    Function scrapes recently rated page on BBFC site\n",
        "    Iterate over each recently rated record and extracts href\n",
        "    For every href, call scrape_film function and get dictionary with movie details\n",
        "    Adds the extracted dictionary into a list and converts the list to a Pandas Dataframe\n",
        "\n",
        "    Returns : Pandas dataframe containing movie details\n",
        "    '''\n",
        "    response_rr = requests.get(f\"https://www.bbfc.co.uk/recently-rated\")\n",
        "    recently_rated_detail = []\n",
        "    if response_rr.status_code == 200:\n",
        "        recently_rated_html_content = response_rr.content\n",
        "        recently_rated_soup = BeautifulSoup(recently_rated_html_content, 'html.parser')\n",
        "        main_recent_added = recently_rated_soup.find('main', class_ = \"Main_Main__46590\")\n",
        "        recent_added_list = main_recent_added.find_all('div', class_ = \"SearchItem_SearchItem__3kbZF\")\n",
        "        for recent_added in recent_added_list:\n",
        "            '''Detailed way to scrape information from movie page(DRY)'''\n",
        "            anchor_tag = recent_added.find('a')\n",
        "            href_rec = anchor_tag.get('href')\n",
        "            recent_details_dict = scrape_film(href_rec)\n",
        "            if type(recent_details_dict) == dict:\n",
        "                recently_rated_detail.append(recent_details_dict)\n",
        "            else:\n",
        "                print(recent_details_dict)\n",
        "\n",
        "            '''Alternate way to scrape information from recent rated page itself(Gives limited information)'''\n",
        "            #recent_dict = {}\n",
        "            #rating_tag = recent_added.find('span', class_ = \"Icon_Icon__9RCS8 SearchItem_Rating__2fbS8\")['aria-label'].split()[1]\n",
        "            #recent_tag_title = anchor_tag.find('h3').text\n",
        "            #category = anchor_tag.find('span').text\n",
        "            #release_date = recent_added.find('div', class_ =\"Type_base__2EnB2 SearchItem_ReleaseDate__21k53\")\n",
        "            # if release_date != None:\n",
        "            #     release_date = release_date.text.split()[2]\n",
        "            # else:\n",
        "            #     release_date = 'N/A'\n",
        "            # print(f\"{recent_tag_title}, {category}\")\n",
        "            # print(href_rec)\n",
        "            # recent_dict[\"recent_tag_title\"] = recent_tag_title\n",
        "            # recent_dict[\"release_date\"] = release_date\n",
        "            # recent_dict[\"rating_tag\"] = rating_tag\n",
        "            # recent_dict[\"href_rec\"] = href_rec\n",
        "            # recent_dict[\"category\"] = category\n",
        "            #recently_rated_detail.append(recent_details_dict)\n",
        "        recent_added_film_df = pd.DataFrame(recently_rated_detail)\n",
        "        json_data_recent = recent_added_film_df.to_json(orient='records')\n",
        "        #print(json_data_recent)\n",
        "        return recent_added_film_df\n",
        "    else:\n",
        "        return f'Recent added page not found with response status: {response_rr.status_code}'\n",
        "\n",
        "\n",
        "\n",
        "def scrape_film(movie_href):\n",
        "    '''\n",
        "    Function scrapes the films page using href of specific film\n",
        "\n",
        "    parameters:\n",
        "    movie_href: string with href of a particular film e.g : /release/dada-q29sbgvjdglvbjpwwc0xmdexmty1\n",
        "\n",
        "    return parameters:\n",
        "    Success scenario : Dictionary of movie details\n",
        "    Failure scenario : String containing error details\n",
        "\n",
        "    '''\n",
        "    response = requests.get(f\"https://www.bbfc.co.uk{movie_href}\")\n",
        "    if response.status_code == 200:\n",
        "        movie_details = {}\n",
        "        movie_html_content = response.content\n",
        "        movie_soup = BeautifulSoup(movie_html_content, 'html.parser')\n",
        "\n",
        "        '''Extracting film title'''\n",
        "        title_h2 = movie_soup.find('h2', class_ = \"MediaOutline_Title__3UY5z\")\n",
        "        span = title_h2.find('span')\n",
        "        title = span.text\n",
        "        movie_details[\"title\"]= title\n",
        "\n",
        "        '''Extracting film rating'''\n",
        "        rating_span = movie_soup.find('span', class_= \"Icon_Icon__9RCS8 MediaOutline_Icon__3mXHF\")\n",
        "        movie_rating = rating_span['aria-label'].split()[1]\n",
        "        movie_details[\"rating\"] = movie_rating\n",
        "\n",
        "        '''Extracting media type'''\n",
        "        media_type_div = movie_soup.find('div', class_ =\"MediaOutline_MediaType__AipEd\")\n",
        "        media_type = media_type_div.text\n",
        "        movie_details[\"media_type\"] = media_type\n",
        "\n",
        "        '''Extracting key details'''\n",
        "        keyList_ul = movie_soup.find('ul', class_ =\"KeyDetails_List__1oCpD\")\n",
        "        key_li_list = keyList_ul.find_all('li', class_ =\"ListItem_ListItem__klTTg\")\n",
        "        key_details = {}\n",
        "        for li in key_li_list:\n",
        "            h4_list = li.find_all('h4', class_ =\"Type_base__2EnB2\")\n",
        "            if h4_list[0].text == 'Release date':\n",
        "                release_date = datetime.datetime.strptime(h4_list[1].text, '%d/%m/%Y').date()\n",
        "                key_details[h4_list[0].text] = str(release_date)\n",
        "            else:\n",
        "                key_details[h4_list[0].text] = h4_list[1].text\n",
        "        movie_details[\"key_details\"] = key_details\n",
        "\n",
        "        '''Extracting content advice data'''\n",
        "        content_details = movie_soup.find('div', class_ =\"VisualAdvice_VisualAdvice__icKUz\")\n",
        "        if content_details != None:\n",
        "            grid_items = content_details.find_all('div', class_ = \"GridItem_GridItem__Wegeu\")\n",
        "            content_advice = []\n",
        "            for grid_item in grid_items:\n",
        "                advice_details = {}\n",
        "                content_title = grid_item.find('p',class_= \"Type_base__2EnB2\").text\n",
        "                max_rating_count = len(grid_item.find_all('span'))\n",
        "                current_rating_count = max_rating_count - len(grid_item.find_all('span', class_ =\"VisualAdviceRating_unfilled__1D3DY\"))\n",
        "                advice_details[\"content_title\"] = content_title\n",
        "                advice_details[\"content_rating\"] = current_rating_count\n",
        "                advice_details[\"max_rating\"] = max_rating_count\n",
        "                content_advice.append(advice_details)\n",
        "            movie_details[\"content_advice\"] = content_advice\n",
        "        else:\n",
        "            print(f\"content details are not available for {movie_details['title']}\")\n",
        "\n",
        "        '''returning movie details dictionary with all the details'''\n",
        "        return movie_details\n",
        "    else:\n",
        "        return f'Movie not found with response status: {response.status_code}'\n",
        "\n",
        "def scrape_spreadsheet():\n",
        "    '''\n",
        "    Function scrapes the given excel sheet and returns the list of movies in the excel\n",
        "\n",
        "    Return:\n",
        "    list of movies in the sheet. e.g ['Creed III', 'Dada',...]\n",
        "    '''\n",
        "    response_spr = requests.get(\"https://docs.google.com/spreadsheets/d/1gdNU75_RPG69bsuAFQpZu670sHK9EzTwZWSLUERhMZ4/edit#gid=0\")\n",
        "    title_list = []\n",
        "    if response_spr.status_code == 200:\n",
        "      response_scr_cont = response_spr.content\n",
        "      content_html_spr = BeautifulSoup(response_scr_cont, 'html.parser')\n",
        "      xl_div = content_html_spr.find('div',id = '0-grid-table-container')\n",
        "      tbody = xl_div.find('tbody')\n",
        "      tr_spr_list = tbody.find_all('tr')\n",
        "      for tr_spr in tr_spr_list:\n",
        "          td = tr_spr.find('td')\n",
        "          if td.text != '' and td.text != 'Title':\n",
        "              title_list.append(td.text)\n",
        "    else:\n",
        "      print(f\"Excel doc not found\")\n",
        "    return title_list\n",
        "\n",
        "''''''\n",
        "def scrape_query_result():\n",
        "    '''\n",
        "    Function iterates over a list of title extracted from scrape_spreadsheet() function\n",
        "    Creates a query URL for each title and extracts query result page\n",
        "    For every first query result extract the href and calls scrape_film function\n",
        "    Adds the extracted dictionary into a list and converts the list to a Pandas Dataframe\n",
        "\n",
        "    Returns : Pandas dataframe containing movie details\n",
        "\n",
        "\n",
        "    '''\n",
        "    title_list = scrape_spreadsheet()\n",
        "    title_details_list = []\n",
        "    for title in title_list:\n",
        "        url_title =f\"https://www.bbfc.co.uk/search?q={title}\"\n",
        "        response_title = requests.get(url_title)\n",
        "        if response_title.status_code == 200:\n",
        "            query_soup = BeautifulSoup(response_title.content, 'html.parser')\n",
        "            result_div = query_soup.find('div', class_ =\"GridItem_GridItem__Wegeu GridItem_m-100__32Nyd GridItem_t-100__Pq2Bq GridItem_tl-67__1OyMa\")\n",
        "            not_found = result_div.find('p',class_='BBFCSearchLayout_Title__1GdfR')\n",
        "            if not_found == None:\n",
        "                first_title = result_div.find('div', class_ =\"SearchItem_SearchItem__3kbZF\")\n",
        "                anchor_tag_title = first_title.find('a')\n",
        "                href_title = anchor_tag_title.get('href')\n",
        "                title_details_dict = scrape_film(href_title)\n",
        "                if type(title_details_dict) == dict:\n",
        "                    title_details_list.append(title_details_dict)\n",
        "                else:\n",
        "                    print(title_details_dict)\n",
        "            else:\n",
        "                print(f\"No results found for movie {title}\")\n",
        "        else:\n",
        "            print(f\"Query page returned with status code : {response_title.status_code} for {title}\")\n",
        "    title_details_df = pd.DataFrame(title_details_list)\n",
        "    json_data = title_details_df.to_json(orient='records',date_format='iso')\n",
        "    #print(json_data)\n",
        "    return title_details_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8827SOcz6e7"
      },
      "source": [
        "Use the below code to run the above functions\n",
        "\n",
        "1. To extract a speoific movie details call the function as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GnRT0w80dy_"
      },
      "outputs": [],
      "source": [
        "scrape_film(\"/release/dada-q29sbgvjdglvbjpwwc0xmdexmty1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jzdHZ660iBd"
      },
      "source": [
        "2. To extract movie details for each file in the recently Rated Page  call the functions as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWqb3ZuP0rms"
      },
      "outputs": [],
      "source": [
        "recent_page_film_scrape()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzre1lHf0vjh"
      },
      "source": [
        "3. To extract the list of Titles from the spreadsheet , call the function as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRjazPlB0vMO"
      },
      "outputs": [],
      "source": [
        "scrape_spreadsheet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLP1fljD03nF"
      },
      "source": [
        "4. To extract the details for each title in the spreadsheet , call the function as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej--nlPK1CLC"
      },
      "outputs": [],
      "source": [
        "scrape_query_result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OScLuXuw2hHr"
      },
      "source": [
        "Results extracted in JSON format for both the dataframes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
